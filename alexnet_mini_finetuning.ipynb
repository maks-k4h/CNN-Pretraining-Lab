{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import CelebA\n",
    "from AlexNet.MyAlexNetPretrainer import AlexNetMini, AlexNetPretrainer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "standard_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.PILToTensor(),\n",
    "    torchvision.transforms.ConvertImageDtype(torch.float),\n",
    "    torchvision.transforms.Resize(size=223),\n",
    "    torchvision.transforms.CenterCrop(size=223)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = CelebA('', download=False, split='train', transform=standard_transform)\n",
    "valid_dataset = CelebA('', download=False, split='valid', transform=standard_transform)\n",
    "test_dataset = CelebA('', download=False, split='test', transform=standard_transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pretrainer = AlexNetPretrainer()\n",
    "pretrainer.load_state_dict(torch.load('celeba_pretrainer.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AlexNetMini(40)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pretrainer.appy_weights(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_error(dataloader, model, batches_to_test=0):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, epochs):\n",
    "\n",
    "    N = len(dataloader)\n",
    "    Nb = max(1, N // 16)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch', epoch + 1)\n",
    "        epoch_losses = []\n",
    "        batches_losses = []\n",
    "\n",
    "        for bn, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            # reporting the number of batches done\n",
    "            if (bn + 1) % Nb == 0:\n",
    "                print('[{:6} | {:6}] loss: {}'.format(bn + 1, N, statistics.mean(batches_losses)))\n",
    "                batches_losses.clear()\n",
    "\n",
    "            # generating the code and the reconstruction and estimating the loss\n",
    "            y_h = model.forward(x)\n",
    "            loss = loss_fn(y, y_h)\n",
    "\n",
    "            # tracking the loss\n",
    "            epoch_losses.append(float(loss))\n",
    "            batches_losses.append(float(loss))\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch loss:', statistics.mean(epoch_losses), '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
