{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import CelebA\n",
    "from AlexNet.MyAlexNetPretrainer import AlexNetMini, AlexNetPretrainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The daily quota of the file img_align_celeba.zip is exceeded and it can't be downloaded. This is a limitation of Google Drive and can only be overcome by trying again later.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mCelebA\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mall\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Python/ML/MLEnv/lib/python3.9/site-packages/torchvision/datasets/celeba.py:80\u001B[0m, in \u001B[0;36mCelebA.__init__\u001B[0;34m(self, root, split, target_type, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget_transform is specified but target_type is empty\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[0;32m---> 80\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_integrity():\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Python/ML/MLEnv/lib/python3.9/site-packages/torchvision/datasets/celeba.py:150\u001B[0m, in \u001B[0;36mCelebA.download\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (file_id, md5, filename) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_list:\n\u001B[0;32m--> 150\u001B[0m     \u001B[43mdownload_file_from_google_drive\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_folder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m extract_archive(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_folder, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg_align_celeba.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/Documents/Python/ML/MLEnv/lib/python3.9/site-packages/torchvision/datasets/utils.py:259\u001B[0m, in \u001B[0;36mdownload_file_from_google_drive\u001B[0;34m(file_id, root, filename, md5)\u001B[0m\n\u001B[1;32m    256\u001B[0m         api_response, content \u001B[38;5;241m=\u001B[39m _extract_gdrive_api_response(response)\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m api_response \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuota exceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 259\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    260\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe daily quota of the file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is exceeded and it \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    261\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt be downloaded. This is a limitation of Google Drive \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    262\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand can only be overcome by trying again later.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    263\u001B[0m         )\n\u001B[1;32m    265\u001B[0m     _save_response_content(content, fpath)\n\u001B[1;32m    267\u001B[0m \u001B[38;5;66;03m# In case we deal with an unhandled GDrive API response, the file should be smaller than 10kB and contain only text\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The daily quota of the file img_align_celeba.zip is exceeded and it can't be downloaded. This is a limitation of Google Drive and can only be overcome by trying again later."
     ]
    }
   ],
   "source": [
    "train_dataset = CelebA('', download=True, split='all')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# cannot load the dataset due to Drive's limitation, so work with random data (noise)\n",
    "data = [torch.rand(3, 223, 223) for i in range(100)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "pretrainer = AlexNetPretrainer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def reconstruction_error(model):\n",
    "    recon = pretrainer.forward(data[0])\n",
    "    print('L1 error:', (data[0] - recon).absolute().mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code size: torch.Size([128, 6, 6])\n",
      "L1 error: tensor(0.4866, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reconstruction_error(pretrainer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining  1 th layer for AlexNet Mini.\n",
      "Epochs: 50\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 1e-05\n",
      "Epoch 1\n",
      "Epoch loss: 0.4433431506156921\n",
      "Epoch 2\n",
      "Epoch loss: 0.3240035444498062\n",
      "Epoch 3\n",
      "Epoch loss: 0.2645921856164932\n",
      "Epoch 4\n",
      "Epoch loss: 0.25584533512592317\n",
      "Epoch 5\n",
      "Epoch loss: 0.2541244953870773\n",
      "Epoch 6\n",
      "Epoch loss: 0.2517428398132324\n",
      "Epoch 7\n",
      "Epoch loss: 0.250601002573967\n",
      "Epoch 8\n",
      "Epoch loss: 0.25030631124973296\n",
      "Epoch 9\n",
      "Epoch loss: 0.2501776874065399\n",
      "Epoch 10\n",
      "Epoch loss: 0.2500814512372017\n",
      "Epoch 11\n",
      "Epoch loss: 0.25002284348011017\n",
      "Epoch 12\n",
      "Epoch loss: 0.2499889612197876\n",
      "Epoch 13\n",
      "Epoch loss: 0.24996513575315477\n",
      "Epoch 14\n",
      "Epoch loss: 0.24994623214006423\n",
      "Epoch 15\n",
      "Epoch loss: 0.24993016719818115\n",
      "Epoch 16\n",
      "Epoch loss: 0.24991612136363983\n",
      "Epoch 17\n",
      "Epoch loss: 0.24990330785512924\n",
      "Epoch 18\n",
      "Epoch loss: 0.24989133775234224\n",
      "Epoch 19\n",
      "Epoch loss: 0.24987993985414506\n",
      "Epoch 20\n",
      "Epoch loss: 0.24986879229545594\n",
      "Epoch 21\n",
      "Epoch loss: 0.24985788017511368\n",
      "Epoch 22\n",
      "Epoch loss: 0.24984701424837114\n",
      "Epoch 23\n",
      "Epoch loss: 0.2498363733291626\n",
      "Epoch 24\n",
      "Epoch loss: 0.24982544183731079\n",
      "Epoch 25\n",
      "Epoch loss: 0.24981452524662018\n",
      "Epoch 26\n",
      "Epoch loss: 0.2498035430908203\n",
      "Epoch 27\n",
      "Epoch loss: 0.24979242235422133\n",
      "Epoch 28\n",
      "Epoch loss: 0.24978084713220597\n",
      "Epoch 29\n",
      "Epoch loss: 0.24976927638053895\n",
      "Epoch 30\n",
      "Epoch loss: 0.24975745677947997\n",
      "Epoch 31\n",
      "Epoch loss: 0.24974522292613982\n",
      "Epoch 32\n",
      "Epoch loss: 0.2497325971722603\n",
      "Epoch 33\n",
      "Epoch loss: 0.2497193619608879\n",
      "Epoch 34\n",
      "Epoch loss: 0.24970615059137344\n",
      "Epoch 35\n",
      "Epoch loss: 0.24969231635332106\n",
      "Epoch 36\n",
      "Epoch loss: 0.24967844188213348\n",
      "Epoch 37\n",
      "Epoch loss: 0.2496643915772438\n",
      "Epoch 38\n",
      "Epoch loss: 0.24964954406023027\n",
      "Epoch 39\n",
      "Epoch loss: 0.24963426142930983\n",
      "Epoch 40\n",
      "Epoch loss: 0.2496187999844551\n",
      "Epoch 41\n",
      "Epoch loss: 0.2496027320623398\n",
      "Epoch 42\n",
      "Epoch loss: 0.2495863616466522\n",
      "Epoch 43\n",
      "Epoch loss: 0.24956982731819152\n",
      "Epoch 44\n",
      "Epoch loss: 0.24955238848924638\n",
      "Epoch 45\n",
      "Epoch loss: 0.24953476786613465\n",
      "Epoch 46\n",
      "Epoch loss: 0.2495167374610901\n",
      "Epoch 47\n",
      "Epoch loss: 0.2494981750845909\n",
      "Epoch 48\n",
      "Epoch loss: 0.24947944283485413\n",
      "Epoch 49\n",
      "Epoch loss: 0.24946019798517227\n",
      "Epoch 50\n",
      "Epoch loss: 0.24944035857915878\n",
      "Pretraining  2 th layer for AlexNet Mini.\n",
      "Epochs: 50\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 1e-05\n",
      "Epoch 1\n",
      "Epoch loss: 0.07943015694618225\n",
      "Epoch 2\n",
      "Epoch loss: 0.07059653624892234\n",
      "Epoch 3\n",
      "Epoch loss: 0.06267832927405834\n",
      "Epoch 4\n",
      "Epoch loss: 0.056932584196329114\n",
      "Epoch 5\n",
      "Epoch loss: 0.05240706317126751\n",
      "Epoch 6\n",
      "Epoch loss: 0.048668214678764345\n",
      "Epoch 7\n",
      "Epoch loss: 0.04549268893897533\n",
      "Epoch 8\n",
      "Epoch loss: 0.0427865419536829\n",
      "Epoch 9\n",
      "Epoch loss: 0.04048463031649589\n",
      "Epoch 10\n",
      "Epoch loss: 0.03856827579438686\n",
      "Epoch 11\n",
      "Epoch loss: 0.03703532107174397\n",
      "Epoch 12\n",
      "Epoch loss: 0.035862719640135765\n",
      "Epoch 13\n",
      "Epoch loss: 0.03499616272747517\n",
      "Epoch 14\n",
      "Epoch loss: 0.03437034264206886\n",
      "Epoch 15\n",
      "Epoch loss: 0.03392629809677601\n",
      "Epoch 16\n",
      "Epoch loss: 0.03361499831080437\n",
      "Epoch 17\n",
      "Epoch loss: 0.03339871689677239\n",
      "Epoch 18\n",
      "Epoch loss: 0.03324888460338116\n",
      "Epoch 19\n",
      "Epoch loss: 0.03314432054758072\n",
      "Epoch 20\n",
      "Epoch loss: 0.0330711841583252\n",
      "Epoch 21\n",
      "Epoch loss: 0.03301911875605583\n",
      "Epoch 22\n",
      "Epoch loss: 0.0329823087900877\n",
      "Epoch 23\n",
      "Epoch loss: 0.03295486532151699\n",
      "Epoch 24\n",
      "Epoch loss: 0.032934554666280744\n",
      "Epoch 25\n",
      "Epoch loss: 0.032918871566653254\n",
      "Epoch 26\n",
      "Epoch loss: 0.032905764505267145\n",
      "Epoch 27\n",
      "Epoch loss: 0.032895616441965106\n",
      "Epoch 28\n",
      "Epoch loss: 0.03288792073726654\n",
      "Epoch 29\n",
      "Epoch loss: 0.032880692183971404\n",
      "Epoch 30\n",
      "Epoch loss: 0.032874101772904396\n",
      "Epoch 31\n",
      "Epoch loss: 0.03287003114819527\n",
      "Epoch 32\n",
      "Epoch loss: 0.03286343477666378\n",
      "Epoch 33\n",
      "Epoch loss: 0.03286139294505119\n",
      "Epoch 34\n",
      "Epoch loss: 0.03285789974033833\n",
      "Epoch 35\n",
      "Epoch loss: 0.03285588510334492\n",
      "Epoch 36\n",
      "Epoch loss: 0.03285293392837048\n",
      "Epoch 37\n",
      "Epoch loss: 0.03284871056675911\n",
      "Epoch 38\n",
      "Epoch loss: 0.032846761867403984\n",
      "Epoch 39\n",
      "Epoch loss: 0.03284452930092811\n",
      "Epoch 40\n",
      "Epoch loss: 0.03284588232636452\n",
      "Epoch 41\n",
      "Epoch loss: 0.03283846527338028\n",
      "Epoch 42\n",
      "Epoch loss: 0.03283578976988792\n",
      "Epoch 43\n",
      "Epoch loss: 0.03283723928034306\n",
      "Epoch 44\n",
      "Epoch loss: 0.03283813185989857\n",
      "Epoch 45\n",
      "Epoch loss: 0.032836780324578284\n",
      "Epoch 46\n",
      "Epoch loss: 0.032831520214676856\n",
      "Epoch 47\n",
      "Epoch loss: 0.03283186219632626\n",
      "Epoch 48\n",
      "Epoch loss: 0.03283236883580685\n",
      "Epoch 49\n",
      "Epoch loss: 0.03282589167356491\n",
      "Epoch 50\n",
      "Epoch loss: 0.03282927088439465\n",
      "Pretraining  3 th layer for AlexNet Mini.\n",
      "Epochs: 50\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 1e-05\n",
      "Epoch 1\n",
      "Epoch loss: 0.015502833016216754\n",
      "Epoch 2\n",
      "Epoch loss: 0.010054325312376022\n",
      "Epoch 3\n",
      "Epoch loss: 0.005263284733518958\n",
      "Epoch 4\n",
      "Epoch loss: 0.0025752876652404668\n",
      "Epoch 5\n",
      "Epoch loss: 0.0017673774855211377\n",
      "Epoch 6\n",
      "Epoch loss: 0.00131699088960886\n",
      "Epoch 7\n",
      "Epoch loss: 0.0010807518614456058\n",
      "Epoch 8\n",
      "Epoch loss: 0.000951941660605371\n",
      "Epoch 9\n",
      "Epoch loss: 0.0008725115505512804\n",
      "Epoch 10\n",
      "Epoch loss: 0.0008157516713254154\n",
      "Epoch 11\n",
      "Epoch loss: 0.0007688762794714421\n",
      "Epoch 12\n",
      "Epoch loss: 0.0007276322925463319\n",
      "Epoch 13\n",
      "Epoch loss: 0.0006903050234541297\n",
      "Epoch 14\n",
      "Epoch loss: 0.0006556101026944817\n",
      "Epoch 15\n",
      "Epoch loss: 0.0006226085009984672\n",
      "Epoch 16\n",
      "Epoch loss: 0.000591254886239767\n",
      "Epoch 17\n",
      "Epoch loss: 0.0005612098146229982\n",
      "Epoch 18\n",
      "Epoch loss: 0.0005320327007211744\n",
      "Epoch 19\n",
      "Epoch loss: 0.0005058221984654665\n",
      "Epoch 20\n",
      "Epoch loss: 0.0004802629788173363\n",
      "Epoch 21\n",
      "Epoch loss: 0.00045688867103308437\n",
      "Epoch 22\n",
      "Epoch loss: 0.00043457213905639946\n",
      "Epoch 23\n",
      "Epoch loss: 0.0004109010245883837\n",
      "Epoch 24\n",
      "Epoch loss: 0.0003894816298270598\n",
      "Epoch 25\n",
      "Epoch loss: 0.0003695515333674848\n",
      "Epoch 26\n",
      "Epoch loss: 0.00034984055964741855\n",
      "Epoch 27\n",
      "Epoch loss: 0.0003323365555843338\n",
      "Epoch 28\n",
      "Epoch loss: 0.00031343905720859766\n",
      "Epoch 29\n",
      "Epoch loss: 0.000295077747432515\n",
      "Epoch 30\n",
      "Epoch loss: 0.00027674826269503684\n",
      "Epoch 31\n",
      "Epoch loss: 0.00025915190926752987\n",
      "Epoch 32\n",
      "Epoch loss: 0.00024244012602139264\n",
      "Epoch 33\n",
      "Epoch loss: 0.0002263116941321641\n",
      "Epoch 34\n",
      "Epoch loss: 0.00021126692736288532\n",
      "Epoch 35\n",
      "Epoch loss: 0.000194928098062519\n",
      "Epoch 36\n",
      "Epoch loss: 0.00017944646533578633\n",
      "Epoch 37\n",
      "Epoch loss: 0.00016438017191831023\n",
      "Epoch 38\n",
      "Epoch loss: 0.0001487156900111586\n",
      "Epoch 39\n",
      "Epoch loss: 0.0001314874767558649\n",
      "Epoch 40\n",
      "Epoch loss: 0.00011322206555632874\n",
      "Epoch 41\n",
      "Epoch loss: 9.269626825698651e-05\n",
      "Epoch 42\n",
      "Epoch loss: 9.020087818498724e-05\n",
      "Epoch 43\n",
      "Epoch loss: 8.996851538540795e-05\n",
      "Epoch 44\n",
      "Epoch loss: 9.192728757625445e-05\n",
      "Epoch 45\n",
      "Epoch loss: 9.234120734618046e-05\n",
      "Epoch 46\n",
      "Epoch loss: 9.323629419668577e-05\n",
      "Epoch 47\n",
      "Epoch loss: 9.09776434127707e-05\n",
      "Epoch 48\n",
      "Epoch loss: 9.127302837441675e-05\n",
      "Epoch 49\n",
      "Epoch loss: 9.104555574594997e-05\n",
      "Epoch 50\n",
      "Epoch loss: 8.968076726887376e-05\n",
      "Pretraining  4 th layer for AlexNet Mini.\n",
      "Epochs: 50\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 1e-05\n",
      "Epoch 1\n",
      "Epoch loss: 0.012157531920820475\n",
      "Epoch 2\n",
      "Epoch loss: 0.008647314691916107\n",
      "Epoch 3\n",
      "Epoch loss: 0.005189300328493118\n",
      "Epoch 4\n",
      "Epoch loss: 0.002721755323000252\n",
      "Epoch 5\n",
      "Epoch loss: 0.0014398926636204124\n",
      "Epoch 6\n",
      "Epoch loss: 0.001047402888070792\n",
      "Epoch 7\n",
      "Epoch loss: 0.0008250046579632908\n",
      "Epoch 8\n",
      "Epoch loss: 0.0007074780180118978\n",
      "Epoch 9\n",
      "Epoch loss: 0.0006391506234649569\n",
      "Epoch 10\n",
      "Epoch loss: 0.0005967858829535544\n",
      "Epoch 11\n",
      "Epoch loss: 0.0005643259733915329\n",
      "Epoch 12\n",
      "Epoch loss: 0.0005354840715881437\n",
      "Epoch 13\n",
      "Epoch loss: 0.0005063410848379135\n",
      "Epoch 14\n",
      "Epoch loss: 0.00048187278443947437\n",
      "Epoch 15\n",
      "Epoch loss: 0.00045858701050747184\n",
      "Epoch 16\n",
      "Epoch loss: 0.0004370255657704547\n",
      "Epoch 17\n",
      "Epoch loss: 0.0004130587331019342\n",
      "Epoch 18\n",
      "Epoch loss: 0.00039051387284416705\n",
      "Epoch 19\n",
      "Epoch loss: 0.0003693034173920751\n",
      "Epoch 20\n",
      "Epoch loss: 0.00034839246654883027\n",
      "Epoch 21\n",
      "Epoch loss: 0.00032997178204823284\n",
      "Epoch 22\n",
      "Epoch loss: 0.00030977093556430193\n",
      "Epoch 23\n",
      "Epoch loss: 0.00029134223877917974\n",
      "Epoch 24\n",
      "Epoch loss: 0.0002730265376158059\n",
      "Epoch 25\n",
      "Epoch loss: 0.0002552850404754281\n",
      "Epoch 26\n",
      "Epoch loss: 0.00023785469675203786\n",
      "Epoch 27\n",
      "Epoch loss: 0.00022122977243270724\n",
      "Epoch 28\n",
      "Epoch loss: 0.00020624466706067323\n",
      "Epoch 29\n",
      "Epoch loss: 0.00019091123540420084\n",
      "Epoch 30\n",
      "Epoch loss: 0.00017697177099762484\n",
      "Epoch 31\n",
      "Epoch loss: 0.00016458675381727516\n",
      "Epoch 32\n",
      "Epoch loss: 0.0001482773950556293\n",
      "Epoch 33\n",
      "Epoch loss: 0.00013187059739721007\n",
      "Epoch 34\n",
      "Epoch loss: 0.00011881936807185411\n",
      "Epoch 35\n",
      "Epoch loss: 0.00010456973977852612\n",
      "Epoch 36\n",
      "Epoch loss: 9.40763668040745e-05\n",
      "Epoch 37\n",
      "Epoch loss: 8.144593957695178e-05\n",
      "Epoch 38\n",
      "Epoch loss: 7.060425705276429e-05\n",
      "Epoch 39\n",
      "Epoch loss: 5.83766999625368e-05\n",
      "Epoch 40\n",
      "Epoch loss: 4.988362888980191e-05\n",
      "Epoch 41\n",
      "Epoch loss: 5.062568961875513e-05\n",
      "Epoch 42\n",
      "Epoch loss: 5.28645690792473e-05\n",
      "Epoch 43\n",
      "Epoch loss: 5.3527613636106254e-05\n",
      "Epoch 44\n",
      "Epoch loss: 5.1378567877691236e-05\n",
      "Epoch 45\n",
      "Epoch loss: 5.063593744125683e-05\n",
      "Epoch 46\n",
      "Epoch loss: 5.260192119749263e-05\n",
      "Epoch 47\n",
      "Epoch loss: 5.1945029917987993e-05\n",
      "Epoch 48\n",
      "Epoch loss: 5.701553491235245e-05\n",
      "Epoch 49\n",
      "Epoch loss: 5.5197408437379635e-05\n",
      "Epoch 50\n",
      "Epoch loss: 5.582386111200321e-05\n",
      "Pretraining  5 th layer for AlexNet Mini.\n",
      "Epochs: 50\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 1e-05\n",
      "Epoch 1\n",
      "Epoch loss: 0.012060201074928046\n",
      "Epoch 2\n",
      "Epoch loss: 0.00929404404014349\n",
      "Epoch 3\n",
      "Epoch loss: 0.00615339451469481\n",
      "Epoch 4\n",
      "Epoch loss: 0.0035740917082875967\n",
      "Epoch 5\n",
      "Epoch loss: 0.0018219260382466018\n",
      "Epoch 6\n",
      "Epoch loss: 0.0011609264300204813\n",
      "Epoch 7\n",
      "Epoch loss: 0.0009726873773615808\n",
      "Epoch 8\n",
      "Epoch loss: 0.0007679699861910194\n",
      "Epoch 9\n",
      "Epoch loss: 0.0006219409930054099\n",
      "Epoch 10\n",
      "Epoch loss: 0.0004933673772029579\n",
      "Epoch 11\n",
      "Epoch loss: 0.0003742055530892685\n",
      "Epoch 12\n",
      "Epoch loss: 0.0002639675178215839\n",
      "Epoch 13\n",
      "Epoch loss: 0.00016194613635889255\n",
      "Epoch 14\n",
      "Epoch loss: 6.878804197185673e-05\n",
      "Epoch 15\n",
      "Epoch loss: 3.0694742599735035e-05\n",
      "Epoch 16\n",
      "Epoch loss: 5.1943510334240274e-05\n",
      "Epoch 17\n",
      "Epoch loss: 4.905231071461458e-05\n",
      "Epoch 18\n",
      "Epoch loss: 4.430270346347243e-05\n",
      "Epoch 19\n",
      "Epoch loss: 4.9060118544730355e-05\n",
      "Epoch 20\n",
      "Epoch loss: 4.9001237857737576e-05\n",
      "Epoch 21\n",
      "Epoch loss: 4.496892761380877e-05\n",
      "Epoch 22\n",
      "Epoch loss: 5.0332742830505595e-05\n",
      "Epoch 23\n",
      "Epoch loss: 4.571760146063752e-05\n",
      "Epoch 24\n",
      "Epoch loss: 4.5890443288953975e-05\n",
      "Epoch 25\n",
      "Epoch loss: 5.0102758541470395e-05\n",
      "Epoch 26\n",
      "Epoch loss: 4.877661049249582e-05\n",
      "Epoch 27\n",
      "Epoch loss: 4.534909130597953e-05\n",
      "Epoch 28\n",
      "Epoch loss: 4.8886602235143074e-05\n",
      "Epoch 29\n",
      "Epoch loss: 4.323459543229546e-05\n",
      "Epoch 30\n",
      "Epoch loss: 4.9889151705428957e-05\n",
      "Epoch 31\n",
      "Epoch loss: 4.8343048547394574e-05\n",
      "Epoch 32\n",
      "Epoch loss: 4.7006692693685184e-05\n",
      "Epoch 33\n",
      "Epoch loss: 4.4247803089092486e-05\n",
      "Epoch 34\n",
      "Epoch loss: 5.2194550153217276e-05\n",
      "Epoch 35\n",
      "Epoch loss: 4.628918941307347e-05\n",
      "Epoch 36\n",
      "Epoch loss: 4.5182654139352964e-05\n",
      "Epoch 37\n",
      "Epoch loss: 4.70156879600836e-05\n",
      "Epoch 38\n",
      "Epoch loss: 5.224300330155529e-05\n",
      "Epoch 39\n",
      "Epoch loss: 4.542963324638549e-05\n",
      "Epoch 40\n",
      "Epoch loss: 4.7201456982293164e-05\n",
      "Epoch 41\n",
      "Epoch loss: 4.7086293852771634e-05\n",
      "Epoch 42\n",
      "Epoch loss: 4.675478958233725e-05\n",
      "Epoch 43\n",
      "Epoch loss: 4.7970972809707745e-05\n",
      "Epoch 44\n",
      "Epoch loss: 5.154464524821378e-05\n",
      "Epoch 45\n",
      "Epoch loss: 4.399361641844734e-05\n",
      "Epoch 46\n",
      "Epoch loss: 4.827164812013507e-05\n",
      "Epoch 47\n",
      "Epoch loss: 4.8527617036597806e-05\n",
      "Epoch 48\n",
      "Epoch loss: 4.734802678285632e-05\n",
      "Epoch 49\n",
      "Epoch loss: 4.71869992907159e-05\n",
      "Epoch 50\n",
      "Epoch loss: 5.11566311615752e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    pretrainer.pretrain(dataloader, i + 1, 50, 1e-2, .9, 1e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code size: torch.Size([128, 6, 6])\n",
      "L1 error: tensor(0.2497, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# since we have pure noise, the loss on the first layer couldn't get less than .2494.\n",
    "# Subsequent layers have more efficient parameters inducing negligible error,\n",
    "# so the loss of the entire autoencoder on the first example is .2497 that is hardly grater\n",
    "# that the loss of the first layer alone.\n",
    "# Because we work with noise data, those result only show the ability of the pretrainer to\n",
    "# function, not its effectiveness.\n",
    "reconstruction_error(pretrainer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
